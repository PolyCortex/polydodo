{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naïve Bayes\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure parent folder is in PYTHONPATH\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    cross_validate,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "     confusion_matrix,\n",
    "     classification_report,\n",
    "     f1_score,\n",
    "     cohen_kappa_score,\n",
    "     make_scorer,\n",
    ")\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import (SelectKBest, f_classif)\n",
    "\n",
    "from constants import (\n",
    "    SLEEP_STAGES_VALUES,\n",
    "    N_STAGES,\n",
    "    EPOCH_DURATION,\n",
    ")\n",
    "from model_utils import (\n",
    "    print_hypnogram,\n",
    "    train_test_split_one_subject,\n",
    "    train_test_split_according_to_age,\n",
    "    evaluate_hyperparams_grid,\n",
    "    print_results_cv,\n",
    "    print_results_cv_scores,\n",
    "    get_pipeline,\n",
    "    print_hyperparam_tuning_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the features\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168954, 50)\n",
      "(168954,)\n",
      "Number of subjects:  78\n",
      "Number of nights:  153\n",
      "Subjects available:  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53. 54.\n",
      " 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 70. 71. 72. 73. 74.\n",
      " 75. 76. 77. 80. 81. 82.]\n"
     ]
    }
   ],
   "source": [
    "# position of the subject information and night information in the X matrix\n",
    "SUBJECT_IDX = 0 \n",
    "NIGHT_IDX = 1\n",
    "USE_CONTINUOUS_AGE = False\n",
    "DOWNSIZE_SET = False\n",
    "TEST_SET_SUBJECTS = [0.0, 24.0, 49.0, 71.0]\n",
    "\n",
    "if USE_CONTINUOUS_AGE:\n",
    "    X_file_name = \"../data/x_features-age-continuous.npy\"\n",
    "    y_file_name = \"../data/y_observations-age-continuous.npy\"\n",
    "else:\n",
    "    X_file_name = \"../data/x_features.npy\"\n",
    "    y_file_name = \"../data/y_observations.npy\"\n",
    "    \n",
    "X_init = np.load(X_file_name, allow_pickle=True)\n",
    "y_init = np.load(y_file_name, allow_pickle=True)\n",
    "\n",
    "X_init = np.vstack(X_init)\n",
    "y_init = np.hstack(y_init)\n",
    "\n",
    "print(X_init.shape)\n",
    "print(y_init.shape)\n",
    "print(\"Number of subjects: \", np.unique(X_init[:,SUBJECT_IDX]).shape[0]) # Some subject indexes are skipped, thus total number is below 83 (as we can see in https://physionet.org/content/sleep-edfx/1.0.0/)\n",
    "print(\"Number of nights: \", len(np.unique([f\"{int(x[0])}-{int(x[1])}\" for x in X_init[:,SUBJECT_IDX:NIGHT_IDX+1]])))\n",
    "print(\"Subjects available: \", np.unique(X_init[:,SUBJECT_IDX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected subjects for the test set are:  [0.0, 24.0, 49.0, 71.0]\n",
      "(8123, 50) (160831, 50) (8123,) (160831,)\n"
     ]
    }
   ],
   "source": [
    "X_test, X_train_valid, y_test, y_train_valid = train_test_split_according_to_age(\n",
    "    X_init,\n",
    "    y_init,\n",
    "    use_continuous_age=USE_CONTINUOUS_AGE,\n",
    "    subjects_test=TEST_SET_SUBJECTS)\n",
    "    \n",
    "print(X_test.shape, X_train_valid.shape, y_test.shape, y_train_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB validation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_KFOLDS = 5\n",
    "NB_CATEGORICAL_FEATURES = 2\n",
    "NB_FEATURES = 48\n",
    "CLASSIFIER_PIPELINE_KEY = 'classifier'\n",
    "RANDOM_STATE = 42 \n",
    "\n",
    "def get_cv_iterator(n_splits=2):\n",
    "    return GroupKFold(n_splits=n_splits).split(\n",
    "        X_train_valid, groups=X_train_valid[:,SUBJECT_IDX]\n",
    "    )\n",
    "    \n",
    "def cross_validate_with_confusion_matrix(pipeline, n_fold):\n",
    "    accuracies = []\n",
    "    macro_f1_scores = []\n",
    "    weighted_f1_scores = []\n",
    "    kappa_agreements = []\n",
    "\n",
    "    for train_index, valid_index in get_cv_iterator(n_splits=n_fold):\n",
    "        # We drop the subject and night indexes\n",
    "        X_train, X_valid = X_train_valid[train_index, 2:], X_train_valid[valid_index, 2:]\n",
    "        y_train, y_valid = y_train_valid[train_index], y_train_valid[valid_index]\n",
    "\n",
    "        # Scaling features and model training\n",
    "        training_pipeline = pipeline\n",
    "        training_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Validation\n",
    "        y_valid_pred = training_pipeline.predict(X_valid)\n",
    "\n",
    "        print(\"----------------------------- FOLD RESULTS --------------------------------------\\n\")\n",
    "        current_kappa = cohen_kappa_score(y_valid, y_valid_pred)\n",
    "\n",
    "        print(\"TRAIN:\", train_index, \"VALID:\", valid_index, \"\\n\\n\")\n",
    "        print(confusion_matrix(y_valid, y_valid_pred), \"\\n\")\n",
    "        print(classification_report(y_valid, y_valid_pred, target_names=SLEEP_STAGES_VALUES.keys()), \"\\n\")\n",
    "        print(\"Agreement score (Cohen Kappa): \", current_kappa, \"\\n\")\n",
    "\n",
    "        accuracies.append(round(accuracy_score(y_valid, y_valid_pred),2))\n",
    "        macro_f1_scores.append(f1_score(y_valid, y_valid_pred, average=\"macro\"))\n",
    "        weighted_f1_scores.append(f1_score(y_valid, y_valid_pred, average=\"weighted\"))\n",
    "        kappa_agreements.append(current_kappa)\n",
    "\n",
    "    print_results_cv(accuracies, macro_f1_scores, weighted_f1_scores, kappa_agreements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- FOLD RESULTS --------------------------------------\n",
      "\n",
      "TRAIN: [  2137   2138   2139 ... 158843 158844 158845] VALID: [     0      1      2 ... 160828 160829 160830] \n",
      "\n",
      "\n",
      "[[5796 1195   78   38  545]\n",
      " [ 609  973  396   25 1714]\n",
      " [ 866 1277 5256 2064 3475]\n",
      " [ 126   82  293 2400   30]\n",
      " [ 280 1033  209   13 4031]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W       0.75      0.76      0.76      7652\n",
      "          N1       0.21      0.26      0.24      3717\n",
      "          N2       0.84      0.41      0.55     12938\n",
      "          N3       0.53      0.82      0.64      2931\n",
      "         REM       0.41      0.72      0.52      5566\n",
      "\n",
      "    accuracy                           0.56     32804\n",
      "   macro avg       0.55      0.59      0.54     32804\n",
      "weighted avg       0.65      0.56      0.57     32804\n",
      " \n",
      "\n",
      "Agreement score (Cohen Kappa):  0.447537950695285 \n",
      "\n",
      "----------------------------- FOLD RESULTS --------------------------------------\n",
      "\n",
      "TRAIN: [     0      1      2 ... 160828 160829 160830] VALID: [  5807   5808   5809 ... 158843 158844 158845] \n",
      "\n",
      "\n",
      "[[3932 2070  434  133 1260]\n",
      " [ 128  908 1151   55 1688]\n",
      " [ 242  241 9389 2401 1088]\n",
      " [  20    7   76 2186    0]\n",
      " [  55  376 1488   71 2849]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W       0.90      0.50      0.64      7829\n",
      "          N1       0.25      0.23      0.24      3930\n",
      "          N2       0.75      0.70      0.73     13361\n",
      "          N3       0.45      0.96      0.61      2289\n",
      "         REM       0.41      0.59      0.49      4839\n",
      "\n",
      "    accuracy                           0.60     32248\n",
      "   macro avg       0.55      0.60      0.54     32248\n",
      "weighted avg       0.65      0.60      0.60     32248\n",
      " \n",
      "\n",
      "Agreement score (Cohen Kappa):  0.4629062351405733 \n",
      "\n",
      "----------------------------- FOLD RESULTS --------------------------------------\n",
      "\n",
      "TRAIN: [     0      1      2 ... 160828 160829 160830] VALID: [  2137   2138   2139 ... 151913 151914 151915] \n",
      "\n",
      "\n",
      "[[4171 3155  765  152 1171]\n",
      " [ 208 1021 1438  123 1986]\n",
      " [ 494  677 7653 2437 1790]\n",
      " [  35    7   23  958    1]\n",
      " [ 115  750 1013   80 2072]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W       0.83      0.44      0.58      9414\n",
      "          N1       0.18      0.21      0.20      4776\n",
      "          N2       0.70      0.59      0.64     13051\n",
      "          N3       0.26      0.94      0.40      1024\n",
      "         REM       0.30      0.51      0.38      4030\n",
      "\n",
      "    accuracy                           0.49     32295\n",
      "   macro avg       0.45      0.54      0.44     32295\n",
      "weighted avg       0.60      0.49      0.52     32295\n",
      " \n",
      "\n",
      "Agreement score (Cohen Kappa):  0.33264469017325693 \n",
      "\n",
      "----------------------------- FOLD RESULTS --------------------------------------\n",
      "\n",
      "TRAIN: [     0      1      2 ... 160828 160829 160830] VALID: [  4057   4058   4059 ... 121623 121624 121625] \n",
      "\n",
      "\n",
      "[[3696 2272  489   88  729]\n",
      " [ 243  711 1034  156 1237]\n",
      " [ 802  226 8131 2778  955]\n",
      " [  80    5  163 3049    0]\n",
      " [  79  386 1887   62 2866]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W       0.75      0.51      0.61      7274\n",
      "          N1       0.20      0.21      0.20      3381\n",
      "          N2       0.69      0.63      0.66     12892\n",
      "          N3       0.50      0.92      0.65      3297\n",
      "         REM       0.50      0.54      0.52      5280\n",
      "\n",
      "    accuracy                           0.57     32124\n",
      "   macro avg       0.53      0.56      0.53     32124\n",
      "weighted avg       0.60      0.57      0.58     32124\n",
      " \n",
      "\n",
      "Agreement score (Cohen Kappa):  0.4387448394456305 \n",
      "\n",
      "----------------------------- FOLD RESULTS --------------------------------------\n",
      "\n",
      "TRAIN: [     0      1      2 ... 160828 160829 160830] VALID: [ 13884  13885  13886 ... 156772 156773 156774] \n",
      "\n",
      "\n",
      "[[3609 2129  763  369 1018]\n",
      " [ 319  700 1052   89 1775]\n",
      " [ 231  544 7442 2085 1827]\n",
      " [  90   10  280 2276    0]\n",
      " [  69  422 1233   80 2948]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W       0.84      0.46      0.59      7888\n",
      "          N1       0.18      0.18      0.18      3935\n",
      "          N2       0.69      0.61      0.65     12129\n",
      "          N3       0.46      0.86      0.60      2656\n",
      "         REM       0.39      0.62      0.48      4752\n",
      "\n",
      "    accuracy                           0.54     31360\n",
      "   macro avg       0.51      0.55      0.50     31360\n",
      "weighted avg       0.60      0.54      0.55     31360\n",
      " \n",
      "\n",
      "Agreement score (Cohen Kappa):  0.40234998625108576 \n",
      "\n",
      "Mean accuracy          : 0.55 ± 0.037\n",
      "Mean macro F1-score    : 0.51 ± 0.039\n",
      "Mean weighted F1-score : 0.56 ± 0.029\n",
      "Mean Kappa's agreement : 0.42 ± 0.047\n",
      "CPU times: user 2.55 s, sys: 171 ms, total: 2.72 s\n",
      "Wall time: 2.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cross_validate_with_confusion_matrix(get_pipeline(\n",
    "    classifier=GaussianNB()\n",
    "), n_fold=NB_KFOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Agreement score (Cohen Kappa):  0.40234998625108576 \n",
    "\n",
    "Mean accuracy          : 0.55 ± 0.037\n",
    "Mean macro F1-score    : 0.51 ± 0.039\n",
    "Mean weighted F1-score : 0.56 ± 0.029\n",
    "Mean Kappa's agreement : 0.42 ± 0.047\n",
    "CPU times: user 3.13 s, sys: 1.08 s, total: 4.21 s\n",
    "Wall time: 5.75 s\n",
    "```\n",
    "\n",
    "## Dimensionality reduction\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_with_dim_reduction(dim_reduction, pipeline=None):\n",
    "    if pipeline is None:\n",
    "        pipeline = get_pipeline(\n",
    "            classifier=GaussianNB(),\n",
    "            dimension_reduction=dim_reduction\n",
    "        )\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        estimator=pipeline,\n",
    "        X=X_train_valid,\n",
    "        y=y_train_valid,\n",
    "        groups=X_train_valid[:,SUBJECT_IDX],\n",
    "        scoring={\n",
    "            \"agreement\": make_scorer(cohen_kappa_score),\n",
    "            \"accuracy\": 'accuracy',\n",
    "            \"f1-score-macro\": 'f1_macro',\n",
    "            \"f1-score-weighted\": 'f1_weighted',\n",
    "        },\n",
    "        cv=get_cv_iterator(n_splits=5),\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print_results_cv_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    6.9s remaining:   10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy          : 0.68 ± 0.027\n",
      "Mean macro F1-score    : 0.60 ± 0.023\n",
      "Mean weighted F1-score : 0.66 ± 0.025\n",
      "Mean Kappa's agreement : 0.55 ± 0.037\n",
      "CPU times: user 64.9 ms, sys: 86.5 ms, total: 151 ms\n",
      "Wall time: 7.82 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.8s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cross_validate_with_dim_reduction(LinearDiscriminantAnalysis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   12.2s remaining:   18.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy          : 0.53 ± 0.017\n",
      "Mean macro F1-score    : 0.41 ± 0.020\n",
      "Mean weighted F1-score : 0.48 ± 0.026\n",
      "Mean Kappa's agreement : 0.29 ± 0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.7s finished\n"
     ]
    }
   ],
   "source": [
    "cross_validate_with_dim_reduction(PCA(n_components=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   14.8s remaining:   22.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy          : 0.59 ± 0.020\n",
      "Mean macro F1-score    : 0.50 ± 0.018\n",
      "Mean weighted F1-score : 0.56 ± 0.020\n",
      "Mean Kappa's agreement : 0.40 ± 0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.6s finished\n"
     ]
    }
   ],
   "source": [
    "cross_validate_with_dim_reduction(PCA(n_components=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   24.6s remaining:   36.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy          : 0.57 ± 0.014\n",
      "Mean macro F1-score    : 0.47 ± 0.008\n",
      "Mean weighted F1-score : 0.54 ± 0.013\n",
      "Mean Kappa's agreement : 0.38 ± 0.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   25.2s finished\n"
     ]
    }
   ],
   "source": [
    "cross_validate_with_dim_reduction(PCA(n_components=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA gave the best results:\n",
    "\n",
    "```\n",
    "Mean accuracy          : 0.68 ± 0.027\n",
    "Mean macro F1-score    : 0.60 ± 0.023\n",
    "Mean weighted F1-score : 0.66 ± 0.025\n",
    "Mean Kappa's agreement : 0.55 ± 0.037\n",
    "CPU times: user 112 ms, sys: 137 ms, total: 249 ms\n",
    "Wall time: 14 s\n",
    "```\n",
    "\n",
    "## Feature selection\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy          : 0.65 ± 0.026\n",
      "Mean macro F1-score    : 0.55 ± 0.023\n",
      "Mean weighted F1-score : 0.63 ± 0.025\n",
      "Mean Kappa's agreement : 0.51 ± 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.5s remaining:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "cross_validate_with_dim_reduction(None, pipeline=\n",
    "  Pipeline([\n",
    "        ('scaling', ColumnTransformer([\n",
    "            ('pass-through-categorical', 'passthrough', list(range(NB_CATEGORICAL_FEATURES))),\n",
    "            ('scaling-continuous', StandardScaler(copy=False), list(range(NB_CATEGORICAL_FEATURES,NB_FEATURES)))\n",
    "        ])),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=15)),\n",
    "        ('dimension_reduction', LinearDiscriminantAnalysis()),\n",
    "        (CLASSIFIER_PIPELINE_KEY, GaussianNB())\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Parameter {'feature_selection__k': 38} has a score of 0.5547 ± 0.012\n",
      "2. Parameter {'feature_selection__k': 33} has a score of 0.5492 ± 0.012\n",
      "3. Parameter {'feature_selection__k': 30} has a score of 0.5467 ± 0.012\n",
      "4. Parameter {'feature_selection__k': 26} has a score of 0.5403 ± 0.015\n",
      "5. Parameter {'feature_selection__k': 15} has a score of 0.5036 ± 0.007\n",
      "6. Parameter {'feature_selection__k': 12} has a score of 0.4797 ± 0.033\n",
      "7. Parameter {'feature_selection__k': 8} has a score of 0.4645 ± 0.008\n",
      "8. Parameter {'feature_selection__k': 9} has a score of 0.4622 ± 0.009\n",
      "9. Parameter {'feature_selection__k': 4} has a score of 0.4236 ± 0.001\n",
      "10. Parameter {'feature_selection__k': 0} has a score of nan ± nan\n",
      "CPU times: user 3.03 s, sys: 710 ms, total: 3.74 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_hyperparams_grid(\n",
    "    params={\n",
    "        f\"feature_selection__k\": np.random.randint(low=0, high=48, size=10),\n",
    "    },\n",
    "    estimator=Pipeline([\n",
    "        ('scaling', ColumnTransformer([\n",
    "            ('pass-through-categorical', 'passthrough', list(range(NB_CATEGORICAL_FEATURES))),\n",
    "            ('scaling-continuous', StandardScaler(copy=False), list(range(NB_CATEGORICAL_FEATURES,NB_FEATURES)))\n",
    "        ])),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=15)),\n",
    "        ('dimension_reduction', LinearDiscriminantAnalysis()),\n",
    "        (CLASSIFIER_PIPELINE_KEY, GaussianNB())\n",
    "    ]),\n",
    "    X=X_train_valid,\n",
    "    y=y_train_valid,\n",
    "    cv=get_cv_iterator(n_splits=2),\n",
    "    use_randomized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1. Parameter {'feature_selection__k': 46} has a score of 0.5633 ± 0.013\n",
    "2. Parameter {'feature_selection__k': 45} has a score of 0.5628 ± 0.013\n",
    "3. Parameter {'feature_selection__k': 43} has a score of 0.5624 ± 0.013\n",
    "4. Parameter {'feature_selection__k': 25} has a score of 0.5368 ± 0.015\n",
    "5. Parameter {'feature_selection__k': 24} has a score of 0.5357 ± 0.014\n",
    "6. Parameter {'feature_selection__k': 17} has a score of 0.5090 ± 0.009\n",
    "7. Parameter {'feature_selection__k': 12} has a score of 0.4797 ± 0.033\n",
    "8. Parameter {'feature_selection__k': 6} has a score of 0.4361 ± 0.013\n",
    "9. Parameter {'feature_selection__k': 3} has a score of 0.3439 ± 0.001\n",
    "10. Parameter {'feature_selection__k': 0} has a score of nan ± nan\n",
    "CPU times: user 3.28 s, sys: 779 ms, total: 4.06 s\n",
    "Wall time: 28.2 s\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Best combination is to not use feature selection, and to use LDA.\n",
    "\n",
    "## Model testing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.39 s, sys: 803 ms, total: 4.19 s\n",
      "Wall time: 3.42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaling',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('pass-through-categorical',\n",
       "                                                  'passthrough', [0, 1]),\n",
       "                                                 ('scaling-continuous',\n",
       "                                                  StandardScaler(copy=False,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True),\n",
       "                                                  [2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                   11, 12, 13, 14, 15, 16, 17,\n",
       "                                                   18, 19, 20, 21, 22, 23, 24,\n",
       "                                                   25, 26, 27, 28, 29, 30, 31, ...])],\n",
       "                                   verbose=False)),\n",
       "                ('dimension_reduction',\n",
       "                 LinearDiscriminantAnalysis(n_components=None, priors=None,\n",
       "                                            shrinkage=None, solver='svd',\n",
       "                                            store_covariance=False,\n",
       "                                            tol=0.0001)),\n",
       "                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "testing_pipeline = get_pipeline(\n",
    "    classifier=GaussianNB(),\n",
    "    dimension_reduction=LinearDiscriminantAnalysis()\n",
    ")\n",
    "\n",
    "testing_pipeline.fit(X_train_valid[:, 2:], y_train_valid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1406   78   17   27   96]\n",
      " [ 186  221  334    4  238]\n",
      " [  38   85 3176  185  119]\n",
      " [   4    0   66  541    0]\n",
      " [  38  113  350    3  798]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W       0.84      0.87      0.85      1624\n",
      "          N1       0.44      0.22      0.30       983\n",
      "          N2       0.81      0.88      0.84      3603\n",
      "          N3       0.71      0.89      0.79       611\n",
      "         REM       0.64      0.61      0.63      1302\n",
      "\n",
      "    accuracy                           0.76      8123\n",
      "   macro avg       0.69      0.69      0.68      8123\n",
      "weighted avg       0.73      0.76      0.74      8123\n",
      "\n",
      "Agreement score (Cohen Kappa):  0.6537897956170273\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = testing_pipeline.predict(X_test[:,2:])\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=SLEEP_STAGES_VALUES.keys()))\n",
    "\n",
    "print(\"Agreement score (Cohen Kappa): \", cohen_kappa_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results\n",
    "___\n",
    "\n",
    "#### 1) With default parameters\n",
    "____\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           W       0.79      0.44      0.57      1624\n",
    "          N1       0.25      0.30      0.28       983\n",
    "          N2       0.79      0.67      0.72      3603\n",
    "          N3       0.42      0.99      0.59       611\n",
    "         REM       0.53      0.63      0.58      1302\n",
    "\n",
    "    accuracy                           0.60      8123\n",
    "   macro avg       0.56      0.61      0.55      8123\n",
    "weighted avg       0.65      0.60      0.60      8123\n",
    "\n",
    "Agreement score (Cohen Kappa):  0.4626294533458143\n",
    "```\n",
    "\n",
    "#### 2) With LDA\n",
    "___\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           W       0.84      0.87      0.85      1624\n",
    "          N1       0.44      0.22      0.30       983\n",
    "          N2       0.81      0.88      0.84      3603\n",
    "          N3       0.71      0.89      0.79       611\n",
    "         REM       0.64      0.61      0.63      1302\n",
    "\n",
    "    accuracy                           0.76      8123\n",
    "   macro avg       0.69      0.69      0.68      8123\n",
    "weighted avg       0.73      0.76      0.74      8123\n",
    "\n",
    "Agreement score (Cohen Kappa):  0.6537897956170273\n",
    "\n",
    "```\n",
    "#### 3) With LDA + feature selection\n",
    "___\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           W       0.84      0.82      0.83      1624\n",
    "          N1       0.40      0.11      0.17       983\n",
    "          N2       0.81      0.86      0.83      3603\n",
    "          N3       0.73      0.84      0.78       611\n",
    "         REM       0.48      0.64      0.55      1302\n",
    "\n",
    "    accuracy                           0.72      8123\n",
    "   macro avg       0.65      0.65      0.63      8123\n",
    "weighted avg       0.71      0.72      0.70      8123\n",
    "\n",
    "Agreement score (Cohen Kappa):  0.6085186109496423\n",
    "```\n",
    "\n",
    "## Saving trained model\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_DIR = \"../trained_model\"\n",
    "\n",
    "if not os.path.exists(SAVED_DIR):\n",
    "    os.mkdir(SAVED_DIR);\n",
    "\n",
    "if USE_CONTINUOUS_AGE: \n",
    "    joblib.dump(testing_pipeline, f\"{SAVED_DIR}/classifier_gaussiannb_age_continuous.joblib\")\n",
    "else:\n",
    "    joblib.dump(testing_pipeline, f\"{SAVED_DIR}/classifier_gaussiannb.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
