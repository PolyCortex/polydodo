{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & reload trained model with ONNX\n",
    "___\n",
    "\n",
    "This notebook aims to save, reload and check if the model can be correctly serialized through ONNX, and the Scikit-learn ONNX package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import (RandomForestClassifier,\n",
    "                              VotingClassifier)\n",
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             classification_report,\n",
    "                             cohen_kappa_score)\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.helpers.onnx_helper import save_onnx_model\n",
    "from onnxruntime import InferenceSession\n",
    "\n",
    "from models.model_utils import (train_test_split_according_to_age)\n",
    "from constants import (SLEEP_STAGES_VALUES,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate trained pipeline\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT_IDX = 0 \n",
    "NIGHT_IDX = 1\n",
    "USE_CONTINUOUS_AGE = False\n",
    "DOWNSIZE_SET = False\n",
    "TEST_SET_SUBJECTS = [0.0, 24.0, 49.0, 71.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168954, 50)\n",
      "(168954,)\n",
      "Number of subjects:  78\n",
      "Number of nights:  153\n",
      "Subjects available:  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53. 54.\n",
      " 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 70. 71. 72. 73. 74.\n",
      " 75. 76. 77. 80. 81. 82.]\n",
      "Selected subjects for the test set are:  [0.0, 24.0, 49.0, 71.0]\n",
      "(8123, 50) (160831, 50) (8123,) (160831,)\n"
     ]
    }
   ],
   "source": [
    "def load_features():\n",
    "    if USE_CONTINUOUS_AGE:\n",
    "        X_file_name = \"data/x_features-age-continuous.npy\"\n",
    "        y_file_name = \"data/y_observations-age-continuous.npy\"\n",
    "    else:\n",
    "        X_file_name = \"data/x_features.npy\"\n",
    "        y_file_name = \"data/y_observations.npy\"\n",
    "\n",
    "    X_init = np.load(X_file_name, allow_pickle=True)\n",
    "    y_init = np.load(y_file_name, allow_pickle=True)\n",
    "\n",
    "    X_init = np.vstack(X_init)\n",
    "    y_init = np.hstack(y_init)\n",
    "\n",
    "    print(X_init.shape)\n",
    "    print(y_init.shape)\n",
    "    print(\"Number of subjects: \", np.unique(X_init[:,SUBJECT_IDX]).shape[0]) # Some subject indexes are skipped, thus total number is below 83 (as we can see in https://physionet.org/content/sleep-edfx/1.0.0/)\n",
    "    print(\"Number of nights: \", len(np.unique([f\"{int(x[0])}-{int(x[1])}\" for x in X_init[:,SUBJECT_IDX:NIGHT_IDX+1]])))\n",
    "    print(\"Subjects available: \", np.unique(X_init[:,SUBJECT_IDX]))\n",
    "    \n",
    "    return X_init, y_init\n",
    "\n",
    "def split_data(X_init, y_init):\n",
    "    X_test, X_train_valid, y_test, y_train_valid = train_test_split_according_to_age(\n",
    "        X_init,\n",
    "        y_init,\n",
    "        use_continuous_age=USE_CONTINUOUS_AGE,\n",
    "        subjects_test=TEST_SET_SUBJECTS)\n",
    "    \n",
    "    print(X_test.shape, X_train_valid.shape, y_test.shape, y_train_valid.shape)\n",
    "    \n",
    "    return X_test, X_train_valid, y_test, y_train_valid\n",
    "\n",
    "X_init, y_init = load_features()\n",
    "X_test, X_train_valid, y_test, y_train_valid = split_data(X_init, y_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1522   52    2    4   44]\n",
      " [ 240  145  325    1  272]\n",
      " [  38   57 3210  188  110]\n",
      " [   4    0   31  576    0]\n",
      " [  57   83  264    0  898]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W       0.82      0.94      0.87      1624\n",
      "          N1       0.43      0.15      0.22       983\n",
      "          N2       0.84      0.89      0.86      3603\n",
      "          N3       0.75      0.94      0.83       611\n",
      "         REM       0.68      0.69      0.68      1302\n",
      "\n",
      "    accuracy                           0.78      8123\n",
      "   macro avg       0.70      0.72      0.70      8123\n",
      "weighted avg       0.75      0.78      0.76      8123\n",
      "\n",
      "Agreement score (Cohen Kappa):  0.6913101923642638\n"
     ]
    }
   ],
   "source": [
    "def get_voting_classifier_pipeline():\n",
    "    NB_CATEGORICAL_FEATURES = 2\n",
    "    NB_FEATURES = 48\n",
    "\n",
    "    estimator_list = [\n",
    "        ('random_forest', RandomForestClassifier(\n",
    "            random_state=42, # enables deterministic behaviour\n",
    "            n_jobs=-1\n",
    "        )),\n",
    "        ('knn', Pipeline([\n",
    "            ('knn_dim_red', LinearDiscriminantAnalysis()),\n",
    "            ('knn_clf', KNeighborsClassifier(\n",
    "                weights='uniform',\n",
    "                n_neighbors=300,\n",
    "                leaf_size=100,\n",
    "                metric='chebyshev',\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])),\n",
    "    ]\n",
    "        \n",
    "    return Pipeline([\n",
    "        ('scaling', ColumnTransformer([\n",
    "            ('pass-through-categorical', 'passthrough', list(range(NB_CATEGORICAL_FEATURES))),\n",
    "            ('scaling-continuous', StandardScaler(copy=False), list(range(NB_CATEGORICAL_FEATURES,NB_FEATURES)))\n",
    "        ])),\n",
    "        ('voting_clf', VotingClassifier(\n",
    "            estimators=estimator_list,\n",
    "            voting='soft',\n",
    "            weights=np.array([0.83756205, 0.16243795]),\n",
    "            flatten_transform=False,\n",
    "            n_jobs=-1,\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "testing_pipeline = get_voting_classifier_pipeline()\n",
    "testing_pipeline.fit(X_train_valid[:, 2:], y_train_valid)\n",
    "y_test_pred = testing_pipeline.predict(X_test[:,2:])\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred, target_names=SLEEP_STAGES_VALUES.keys()))\n",
    "print(\"Agreement score (Cohen Kappa): \", cohen_kappa_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving pipeline to ONNX\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<class 'sklearn.pipeline.Pipeline'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-da92b5b1560b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     initial_types=[(\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m'float_input'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mFloatTensorType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     )]\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/skl2onnx/convert.py\u001b[0m in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, dtype, intermediate, white_op, black_op, final_types)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;31m# Convert our Topology object into ONNX. The outcome is an ONNX model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     onnx_model = convert_topology(topology, name, doc_string, target_opset,\n\u001b[0;32m--> 154\u001b[0;31m                                   dtype=dtype, options=options)\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mintermediate\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0monnx_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, channel_first_inputs, dtype, options)\u001b[0m\n\u001b[1;32m   1052\u001b[0m                               type(getattr(operator, 'raw_model', None))))\n\u001b[1;32m   1053\u001b[0m         \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m         \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;31m# Create a graph from its main components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/skl2onnx/common/_registration.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_operator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_allowed_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_operator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_allowed_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/skl2onnx/operator_converters/voting_classifier.py\u001b[0m in \u001b[0;36mconvert_voting_classifier\u001b[0;34m(scope, operator, container)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mop_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn_operator_name_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mthis_operator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeclare_local_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: <class 'sklearn.pipeline.Pipeline'>"
     ]
    }
   ],
   "source": [
    "onnx_pipeline = convert_sklearn(\n",
    "    testing_pipeline,\n",
    "    initial_types=[(\n",
    "        'float_input',\n",
    "        FloatTensorType([None, X_train_valid[:,2:].shape[1]])\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the Voting classifier conversion do not currently support a Pipeline typed estimator in its estimators list.\n",
    "\n",
    "Considering that;\n",
    "- the option of adding a pipeline as an estimator in the voting classifier is not supported.\n",
    "- the size of a KNearestNeighbor classifier would be too big without its LDA, and that the performance of the RandomForest would be significantly decreased with an LDA beforehand.\n",
    "- the voting classifier had a Cohen Kappa agreement's score of 0.6913 on the testing set, whilst we obtained 0.6916 with the fat Random Forest, and we obtained 0.6879 with the skinny RF.\n",
    "- the voting classifier had a Cohen Kappa agreement's score of 0.62 ± 0.043 on the validation set, whilst we obtained [TO DE DEFINED] with the fat Random Forest, and we obtained 0.62 ± 0.043 with the skinny RF (where the validation set is a CV of 5 partitions and considering subjects)\n",
    "- the size of the small RF is 322.8 Mbytes\n",
    "- the size of the fat RF is 1.91 Gbytes\n",
    "- the size of the voting classifier is 376.8 Mbytes\n",
    "\n",
    "We have decided to temporaly choose to use the skinny random forest, as its performance is quite similar to the voting classifier's and the fat random forest's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate RF trained pipeline\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1512   65    3    3   41]\n",
      " [ 220  147  332    0  284]\n",
      " [  39   45 3212  194  113]\n",
      " [   4    0   32  575    0]\n",
      " [  49   81  284    0  888]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W       0.83      0.93      0.88      1624\n",
      "          N1       0.43      0.15      0.22       983\n",
      "          N2       0.83      0.89      0.86      3603\n",
      "          N3       0.74      0.94      0.83       611\n",
      "         REM       0.67      0.68      0.68      1302\n",
      "\n",
      "    accuracy                           0.78      8123\n",
      "   macro avg       0.70      0.72      0.69      8123\n",
      "weighted avg       0.75      0.78      0.75      8123\n",
      "\n",
      "Agreement score (Cohen Kappa):  0.6879671218212182\n",
      "CPU times: user 3min 41s, sys: 2.5 s, total: 3min 43s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_random_forest_model():\n",
    "    NB_CATEGORICAL_FEATURES = 2\n",
    "    NB_FEATURES = 48\n",
    "    \n",
    "    return Pipeline([\n",
    "        ('scaling', ColumnTransformer([\n",
    "            ('pass-through-categorical', 'passthrough', list(range(NB_CATEGORICAL_FEATURES))),\n",
    "            ('scaling-continuous', StandardScaler(copy=False), list(range(NB_CATEGORICAL_FEATURES,NB_FEATURES)))\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=24,\n",
    "            random_state=42, # enables deterministic behaviour\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "testing_pipeline = get_random_forest_model()\n",
    "testing_pipeline.fit(X_train_valid[:, 2:], y_train_valid)\n",
    "y_test_pred = testing_pipeline.predict(X_test[:,2:])\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred, target_names=SLEEP_STAGES_VALUES.keys()))\n",
    "print(\"Agreement score (Cohen Kappa): \", cohen_kappa_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving with ONNX\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_pipeline = convert_sklearn(\n",
    "    testing_pipeline,\n",
    "    initial_types=[(\n",
    "        'float_input',\n",
    "        FloatTensorType([None, X_train_valid[:,2:].shape[1]])\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_onnx_model(onnx_pipeline, 'trained_model/rf_pipeline.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing ONNX pipeline vs normal pipeline results\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = InferenceSession('trained_model/rf_pipeline.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_onnx = sess.run(None, {'float_input': X_test[:,2:].astype(np.float32)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000738643358365136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(~(y_test_pred_onnx == y_test_pred))/len(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Pipepline drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\n",
    "pydot_graph = GetPydotGraph(onnx_pipeline.graph, name=onnx_pipeline.graph.name, rankdir=\"TP\",\n",
    "                            node_producer=GetOpNodeProducer(\"docstring\"))\n",
    "pydot_graph.write_dot(\"graph.dot\")\n",
    "\n",
    "import os\n",
    "os.system('dot -O -V -Tpng graph.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
