{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting classifier\n",
    "___\n",
    "\n",
    "This model aims to classify sleep stages based on two EEG channel. We will use the features extracted in the `pipeline.ipynb` notebook as the input to a voting classifier. As written in the docs, it \"[...] combines conceptually different machine learning classifiers and uses a majority vote or the average predicted probabilities (soft vote) to predict the class labels.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure parent folder is in PYTHONPATH\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import (GridSearchCV,\n",
    "                                     RandomizedSearchCV,\n",
    "                                     GroupKFold,\n",
    "                                     cross_validate)\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             confusion_matrix,\n",
    "                             classification_report,\n",
    "                             f1_score,\n",
    "                             cohen_kappa_score,\n",
    "                             make_scorer)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import (RandomForestClassifier,\n",
    "                              VotingClassifier)\n",
    "from sklearn.svm import LinearSVC\n",
    "from constants import (SLEEP_STAGES_VALUES,\n",
    "                       N_STAGES,\n",
    "                       EPOCH_DURATION)\n",
    "from model_utils import (print_hypnogram,\n",
    "                         train_test_split_one_subject,\n",
    "                         train_test_split_according_to_age,\n",
    "                         evaluate_hyperparams_grid,\n",
    "                         print_results_cv,\n",
    "                         print_results_cv_scores,\n",
    "                         print_hyperparam_tuning_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the features\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position of the subject information and night information in the X matrix\n",
    "SUBJECT_IDX = 0 \n",
    "NIGHT_IDX = 1\n",
    "USE_CONTINUOUS_AGE = False\n",
    "DOWNSIZE_SET = False\n",
    "TEST_SET_SUBJECTS = [0.0, 24.0, 49.0, 71.0]\n",
    "\n",
    "if USE_CONTINUOUS_AGE:\n",
    "    X_file_name = \"../data/x_features-age-continuous.npy\"\n",
    "    y_file_name = \"../data/y_observations-age-continuous.npy\"\n",
    "else:\n",
    "    X_file_name = \"../data/x_features.npy\"\n",
    "    y_file_name = \"../data/y_observations.npy\"\n",
    "    \n",
    "X_init = np.load(X_file_name, allow_pickle=True)\n",
    "y_init = np.load(y_file_name, allow_pickle=True)\n",
    "\n",
    "X_init = np.vstack(X_init)\n",
    "y_init = np.hstack(y_init)\n",
    "print(X_init.shape)\n",
    "print(y_init.shape)\n",
    "print(\"Number of subjects: \", np.unique(X_init[:,SUBJECT_IDX]).shape[0]) # Some subject indexes are skipped, thus total number is below 83 (as we can see in https://physionet.org/content/sleep-edfx/1.0.0/)\n",
    "print(\"Number of nights: \", len(np.unique([f\"{int(x[0])}-{int(x[1])}\" for x in X_init[:,SUBJECT_IDX:NIGHT_IDX+1]])))\n",
    "print(\"Subjects available: \", np.unique(X_init[:,SUBJECT_IDX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_train_valid, y_test, y_train_valid = train_test_split_according_to_age(\n",
    "    X_init,\n",
    "    y_init,\n",
    "    use_continuous_age=USE_CONTINUOUS_AGE,\n",
    "    subjects_test=TEST_SET_SUBJECTS)\n",
    "    \n",
    "print(X_test.shape, X_train_valid.shape, y_test.shape, y_train_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_KFOLDS = 5\n",
    "NB_CATEGORICAL_FEATURES = 2\n",
    "NB_FEATURES = 48\n",
    "CLASSIFIER_PIPELINE_KEY = 'classifier'\n",
    "RANDOM_STATE = 42 \n",
    "\n",
    "def get_cv_iterator(n_splits=2):\n",
    "    return GroupKFold(n_splits=n_splits).split(\n",
    "        X_train_valid, groups=X_train_valid[:,SUBJECT_IDX]\n",
    "    )\n",
    "    \n",
    "def cross_validate_with_confusion_matrix(pipeline, n_fold):\n",
    "    accuracies = []\n",
    "    macro_f1_scores = []\n",
    "    weighted_f1_scores = []\n",
    "    kappa_agreements = []\n",
    "    emission_matrix = np.zeros((N_STAGES,N_STAGES))\n",
    "\n",
    "    for train_index, valid_index in get_cv_iterator(n_splits=n_fold):\n",
    "        # We drop the subject and night indexes\n",
    "        X_train, X_valid = X_train_valid[train_index, 2:], X_train_valid[valid_index, 2:]\n",
    "        y_train, y_valid = y_train_valid[train_index], y_train_valid[valid_index]\n",
    "\n",
    "        # Scaling features and model training\n",
    "        training_pipeline = pipeline\n",
    "        training_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Validation\n",
    "        y_valid_pred = training_pipeline.predict(X_valid)\n",
    "\n",
    "        print(\"----------------------------- FOLD RESULTS --------------------------------------\\n\")\n",
    "        current_kappa = cohen_kappa_score(y_valid, y_valid_pred)\n",
    "\n",
    "        print(\"TRAIN:\", train_index, \"VALID:\", valid_index, \"\\n\\n\")\n",
    "        print(confusion_matrix(y_valid, y_valid_pred), \"\\n\")\n",
    "        print(classification_report(y_valid, y_valid_pred, target_names=SLEEP_STAGES_VALUES.keys()), \"\\n\")\n",
    "        print(\"Agreement score (Cohen Kappa): \", current_kappa, \"\\n\")\n",
    "\n",
    "        accuracies.append(round(accuracy_score(y_valid, y_valid_pred),2))\n",
    "        macro_f1_scores.append(f1_score(y_valid, y_valid_pred, average=\"macro\"))\n",
    "        weighted_f1_scores.append(f1_score(y_valid, y_valid_pred, average=\"weighted\"))\n",
    "        kappa_agreements.append(current_kappa)\n",
    "        \n",
    "        for y_pred, y_true in zip(y_valid_pred, y_valid):\n",
    "            emission_matrix[y_true, y_pred] += 1\n",
    "\n",
    "    print_results_cv(accuracies, macro_f1_scores, weighted_f1_scores, kappa_agreements)\n",
    "    return emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(with_svc=True, with_knn=True, with_rf=True):\n",
    "    NB_CATEGORICAL_FEATURES = 2\n",
    "    NB_FEATURES = 48\n",
    "    estimator_list = []\n",
    "    \n",
    "    if with_rf:\n",
    "        rf_clf = RandomForestClassifier(\n",
    "            random_state=42, # enables deterministic behaviour\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        estimator_list.append(('random_forest', rf_clf))\n",
    "\n",
    "    if with_knn:\n",
    "        knn_clf = Pipeline([\n",
    "            ('knn_dim_red', LinearDiscriminantAnalysis()),\n",
    "            ('knn_clf', KNeighborsClassifier(\n",
    "                weights='uniform',\n",
    "                n_neighbors=300,\n",
    "                leaf_size=100,\n",
    "                metric='chebyshev',\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "        estimator_list.append(('knn', knn_clf))\n",
    "\n",
    "    if with_svc:\n",
    "        svc_clf = Pipeline([\n",
    "            ('svc_dim_red', PCA(n_components=35)),\n",
    "            ('svc_clf', LinearSVC(\n",
    "                dual=False,\n",
    "                C=2.105,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=RANDOM_STATE\n",
    "            ))\n",
    "        ])\n",
    "        estimator_list.append(('svc', svc_clf))\n",
    "    \n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=estimator_list,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    return Pipeline([\n",
    "            ('scaling', ColumnTransformer([\n",
    "                ('pass-through-categorical', 'passthrough', list(range(NB_CATEGORICAL_FEATURES))),\n",
    "                ('scaling-continuous', StandardScaler(copy=False), list(range(NB_CATEGORICAL_FEATURES,NB_FEATURES)))\n",
    "            ])),\n",
    "            ('voting_clf', voting_clf)\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "emission_matrix = cross_validate_with_confusion_matrix(\n",
    "    get_pipeline(), 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Mean accuracy          : 0.72 ± 0.030\n",
    "Mean macro F1-score    : 0.64 ± 0.027\n",
    "Mean weighted F1-score : 0.70 ± 0.030\n",
    "Mean Kappa's agreement : 0.61 ± 0.044\n",
    "CPU times: user 1min 4s, sys: 7.75 s, total: 1min 12s\n",
    "Wall time: 5min 52s\n",
    "```\n",
    "## Hyperparameter testing\n",
    "___\n",
    "\n",
    "The hyperparameters of a Voting classifier are:\n",
    "- `estimators`: list of classifier\n",
    "\n",
    "- `voting`: {'hard', 'soft'}\n",
    "    \n",
    "    If ‘hard’, uses predicted class labels for majority rule voting. Else if ‘soft’, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers\n",
    "\n",
    "- `weights`: array-like of shape (n_classifiers,), default=None\n",
    "\n",
    "    Sequence of weights (float or int) to weight the occurrences of predicted class labels (hard voting) or class probabilities before averaging (soft voting). Uses uniform weights if None.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_PIPELINE_KEY = 'voting_clf'\n",
    "N_CLASSIFIER = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. `estimators`\n",
    "___\n",
    "\n",
    "We will check all combinations of our three estimators that have at least two estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for title, pipeline in [\n",
    "#     ('-- all estimators --', get_pipeline()),\n",
    "    ('-- without LinearSVC --', get_pipeline(with_svc=False)),\n",
    "    ('-- without KNN --', get_pipeline(with_knn=False)),\n",
    "#     ('-- without RF --', get_pipeline(with_rf=False))\n",
    "]:\n",
    "    scores = cross_validate(\n",
    "        estimator=pipeline,\n",
    "        X=X_train_valid,\n",
    "        y=y_train_valid,\n",
    "        groups=X_train_valid[:,SUBJECT_IDX],\n",
    "        scoring={\n",
    "            \"agreement\": make_scorer(cohen_kappa_score),\n",
    "            \"accuracy\": 'accuracy',\n",
    "            \"f1-score-macro\": 'f1_macro',\n",
    "            \"f1-score-weighted\": 'f1_weighted',\n",
    "        },\n",
    "        cv=get_cv_iterator(n_splits=),\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(title)\n",
    "    print_results_cv_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st experiment: [all, without_svc, without_knn, without_rf]\n",
    "\n",
    "|Rank| With             |Mean accuracy     |Mean macro F1-score       |Mean weighted F1-score    | Mean Kappa's agreement    |\n",
    "|----|------------------|------------------|--------------------------|--------------------------|---------------------------|\n",
    "|1   | RF,      SVC     | 0.72 ± 0.008     | 0.65 ± 0.008             | 0.71 ± 0.013             | 0.61 ± 0.009              |\n",
    "|2   | RF, KNN          | 0.72 ± 0.010     | 0.63 ± 0.010             | 0.70 ± 0.015             | 0.60 ± 0.012              |\n",
    "|3   | RF, KNN, SVC     | 0.71 ± 0.005     | 0.63 ± 0.006             | 0.69 ± 0.011             | 0.60 ± 0.006              |\n",
    "|4   |     KNN, SVC     | 0.70 ± 0.010     | 0.62 ± 0.009             | 0.68 ± 0.015             | 0.58 ± 0.013              |\n",
    "\n",
    "We will run only [RF, KNN] and [RF, SVC] with more splits to have a better view on their scores.\n",
    "\n",
    "2nd experiment: [without_svc, without_knn]\n",
    "\n",
    "|Rank| With             |Mean accuracy     |Mean macro F1-score       |Mean weighted F1-score    | Mean Kappa's agreement    | Time |\n",
    "|----|------------------|------------------|--------------------------|--------------------------|---------------------------|------|\n",
    "|1   | RF,      SVC     | 0.72 ± 0.030     | 0.65 ± 0.030             | 0.71 ± 0.031             | 0.6145 ± 0.043            | 6.0 m|\n",
    "|2   | RF, KNN          | 0.72 ± 0.030     | 0.63 ± 0.029             | 0.69 ± 0.030             | 0.60   ± 0.043            | 6.2 m|\n",
    "\n",
    "We can see we obtain better results without the KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `voting` hyperparameter\n",
    "___\n",
    "\n",
    "Setting this hyperparameter to `hard` involves summing all `predict_proba` results and choosing the class that maximizes this sum. We then have to only include classifier that implements `predict_proba`. In the case of `LinearSVC`, it is not defined, so it is excluded from this tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_hyperparams_grid(\n",
    "    params={\n",
    "        f\"{CLASSIFIER_PIPELINE_KEY}__voting\": ['hard', 'soft'],\n",
    "    },\n",
    "    estimator=get_pipeline(with_svc=False),\n",
    "    X=X_train_valid,\n",
    "    y=y_train_valid,\n",
    "    cv=get_cv_iterator(n_splits=2),\n",
    "    use_randomized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st experiment: `voting` ['hard', 'soft']\n",
    "\n",
    "|Rank| voting           | Test score     |\n",
    "|----|------------------|----------------|\n",
    "|1   | soft             | 0.6155 ± 0.001 |\n",
    "|2   | hard             | 0.5984 ± 0.013 |\n",
    "\n",
    "Wall time: 4min 21s\n",
    "\n",
    "With the preceding results, we will then compare models with RF, KNN with soft voting, which seems promising vs RF, SVC with hard voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF, KNN with soft voting\n",
    "\n",
    "pipeline = get_pipeline(with_svc=False)\n",
    "pipeline.set_params(voting_clf__voting='soft')\n",
    "\n",
    "scores = cross_validate(\n",
    "    estimator=pipeline,\n",
    "    X=X_train_valid,\n",
    "    y=y_train_valid,\n",
    "    groups=X_train_valid[:,SUBJECT_IDX],\n",
    "    scoring={\n",
    "        \"agreement\": make_scorer(cohen_kappa_score),\n",
    "        \"accuracy\": 'accuracy',\n",
    "        \"f1-score-macro\": 'f1_macro',\n",
    "        \"f1-score-weighted\": 'f1_weighted',\n",
    "    },\n",
    "    cv=get_cv_iterator(n_splits=5),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print_results_cv_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['test_agreement'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Rank| With             |Mean accuracy     |Mean macro F1-score       |Mean weighted F1-score    | Mean Kappa's agreement    | Time |\n",
    "|----|------------------|------------------|--------------------------|--------------------------|---------------------------|------|\n",
    "|1   | RF, SVC (hard)   | 0.72 ± 0.030     | 0.65 ± 0.030             | 0.71 ± 0.031             | 0.6145 ± 0.043            | 6.0 m|\n",
    "|2   | RF, KNN (soft)   | 0.72 ± 0.031     | 0.63 ± 0.026             | 0.70 ± 0.030             | 0.6154 ± 0.043            | 5.4 m|\n",
    "\n",
    "Both models are pretty much equivalent.\n",
    "\n",
    "#### 3. `weights` hyperparam\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = get_pipeline(with_svc=False)\n",
    "pipeline.set_params(voting_clf__voting='soft')\n",
    "\n",
    "evaluate_hyperparams_grid(\n",
    "    params={\n",
    "        f\"{CLASSIFIER_PIPELINE_KEY}__weights\": np.random.dirichlet(np.ones(2),size=40),\n",
    "    },\n",
    "    estimator=pipeline,\n",
    "    X=X_train_valid,\n",
    "    y=y_train_valid,\n",
    "    cv=get_cv_iterator(n_splits=2),\n",
    "    use_randomized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best results gives RF a bigger weight than KNN.\n",
    "\n",
    "|Rank| weights                   | Test score     |\n",
    "|----|---------------------------|----------------|\n",
    "|1   | [0.83756205, 0.16243795]  | 0.6237 ± 0.002 |\n",
    "|2   | [0.84033876, 0.15966124]  | 0.6236 ± 0.002 |\n",
    "|3   | [0.66680774, 0.33319226]  | 0.6233 ± 0.001 |\n",
    "|4   | [0.90868334, 0.09131666]  | 0.6213 ± 0.002 |\n",
    "|5   | [0.95630919, 0.04369081]  | 0.6185 ± 0.003 |\n",
    "|6   | [0.47451369, 0.52548631]  | 0.6185 ± 0.003 |\n",
    "|7   | [0.38562595, 0.61437405]  | 0.6140 ± 0.001 |\n",
    "|8   | [0.1670429, 0.8329571]    | 0.5931 ± 0.001 |\n",
    "|9   | [0.14224379, 0.85775621]  | 0.5912 ± 0.001 |\n",
    "|10  | [0.10095773, 0.89904227]  | 0.5879 ± 0.000 |\n",
    "\n",
    "```\n",
    "CPU times: user 1.32 s, sys: 2.16 s, total: 3.48 s\n",
    "Wall time: 19min 23s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Testing\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "testing_pipeline = get_pipeline(with_svc=False)\n",
    "testing_pipeline.set_params(voting_clf__voting='soft')\n",
    "testing_pipeline.set_params(voting_clf__weights=[0.83756205, 0.16243795])\n",
    "\n",
    "testing_pipeline.fit(X_train_valid[:, 2:], y_train_valid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = testing_pipeline.predict(X_test[:,2:])\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=SLEEP_STAGES_VALUES.keys()))\n",
    "\n",
    "print(\"Agreement score (Cohen Kappa): \", cohen_kappa_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results\n",
    "___\n",
    "\n",
    "#### 1) With default parameters and three classifiers\n",
    "____\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           W       0.76      0.92      0.83      1624\n",
    "          N1       0.45      0.18      0.26       983\n",
    "          N2       0.84      0.87      0.86      3603\n",
    "          N3       0.71      0.95      0.81       611\n",
    "         REM       0.69      0.63      0.66      1302\n",
    "\n",
    "    accuracy                           0.77      8123\n",
    "   macro avg       0.69      0.71      0.69      8123\n",
    "weighted avg       0.74      0.77      0.75      8123\n",
    "\n",
    "Agreement score (Cohen Kappa):  0.6714418913120306\n",
    "```\n",
    "\n",
    "#### 2) With weights, soft voting, with SVC & KNN\n",
    "___\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           W       0.82      0.94      0.87      1624\n",
    "          N1       0.43      0.15      0.22       983\n",
    "          N2       0.84      0.89      0.86      3603\n",
    "          N3       0.75      0.94      0.83       611\n",
    "         REM       0.68      0.69      0.68      1302\n",
    "\n",
    "    accuracy                           0.78      8123\n",
    "   macro avg       0.70      0.72      0.70      8123\n",
    "weighted avg       0.75      0.78      0.76      8123\n",
    "\n",
    "Agreement score (Cohen Kappa):  0.6913101923642638\n",
    "```\n",
    "\n",
    "## Saving trained model\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_DIR = \"../trained_model\"\n",
    "\n",
    "if not os.path.exists(SAVED_DIR):\n",
    "    os.mkdir(SAVED_DIR);\n",
    "\n",
    "if USE_CONTINUOUS_AGE: \n",
    "    joblib.dump(testing_pipeline, f\"{SAVED_DIR}/classifier_voting_age_continuous.joblib\")\n",
    "else:\n",
    "    joblib.dump(testing_pipeline, f\"{SAVED_DIR}/classifier_voting.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{SAVED_DIR}/HMM_emissionprob_voting.npy\", emission_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('py3': conda)",
   "language": "python",
   "name": "python36864bitpy3conda60d5576ae6834cf0a5dc3773043eb4d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
